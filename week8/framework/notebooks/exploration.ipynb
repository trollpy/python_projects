{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c95951",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# CORD-19 Dataset Exploration\\n\",\n",
    "    \"## COVID-19 Research Papers Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook explores the CORD-19 dataset to understand patterns in COVID-19 research publications.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from wordcloud import WordCloud\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import re\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set visualization style\\n\",\n",
    "    \"sns.set_style('whitegrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Libraries imported successfully!')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Loading\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the dataset\\n\",\n",
    "    \"# Use nrows parameter to load a sample for faster exploration\\n\",\n",
    "    \"df = pd.read_csv('metadata.csv', nrows=10000)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f'Dataset loaded with {len(df)} rows and {len(df.columns)} columns')\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Initial Data Exploration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display dataset information\\n\",\n",
    "    \"print('=== Dataset Info ===')\\n\",\n",
    "    \"df.info()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check column names\\n\",\n",
    "    \"print('Column names:')\\n\",\n",
    "    \"print(df.columns.tolist())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display basic statistics\\n\",\n",
    "    \"df.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for missing values\\n\",\n",
    "    \"missing_data = pd.DataFrame({\\n\",\n",
    "    \"    'Column': df.columns,\\n\",\n",
    "    \"    'Missing Count': df.isnull().sum().values,\\n\",\n",
    "    \"    'Missing Percentage': (df.isnull().sum().values / len(df) * 100)\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_data = missing_data[missing_data['Missing Count'] > 0].sort_values(\\n\",\n",
    "    \"    'Missing Percentage', ascending=False\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('\\\\nMissing Data Analysis:')\\n\",\n",
    "    \"print(missing_data)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize missing data\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"missing_data.plot(x='Column', y='Missing Percentage', kind='bar', color='coral')\\n\",\n",
    "    \"plt.title('Missing Data by Column', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Column')\\n\",\n",
    "    \"plt.ylabel('Missing Percentage (%)')\\n\",\n",
    "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Data Cleaning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a clean copy\\n\",\n",
    "    \"df_clean = df.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert publish_time to datetime\\n\",\n",
    "    \"df_clean['publish_time'] = pd.to_datetime(df_clean['publish_time'], errors='coerce')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract year\\n\",\n",
    "    \"df_clean['year'] = df_clean['publish_time'].dt.year\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove rows without title\\n\",\n",
    "    \"df_clean = df_clean.dropna(subset=['title'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create word count features\\n\",\n",
    "    \"df_clean['abstract_word_count'] = df_clean['abstract'].fillna('').apply(\\n\",\n",
    "    \"    lambda x: len(str(x).split())\\n\",\n",
    "    \")\\n\",\n",
    "    \"df_clean['title_word_count'] = df_clean['title'].apply(\\n\",\n",
    "    \"    lambda x: len(str(x).split())\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f'Cleaned dataset shape: {df_clean.shape}')\\n\",\n",
    "    \"print(f'Removed {len(df) - len(df_clean)} rows')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display cleaned data info\\n\",\n",
    "    \"df_clean.info()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Exploratory Data Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.1 Publication Trends Over Time\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Publications by year\\n\",\n",
    "    \"year_counts = df_clean['year'].value_counts().sort_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.bar(year_counts.index, year_counts.values, color='steelblue', edgecolor='black')\\n\",\n",
    "    \"plt.title('COVID-19 Research Publications by Year', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Year', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Number of Publications', fontsize=12)\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Publications by year:')\\n\",\n",
    "    \"print(year_counts)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.2 Top Journals\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Top 15 journals\\n\",\n",
    "    \"top_journals = df_clean['journal'].value_counts().head(15)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"plt.barh(range(len(top_journals)), top_journals.values, color='coral')\\n\",\n",
    "    \"plt.yticks(range(len(top_journals)), top_journals.index)\\n\",\n",
    "    \"plt.title('Top 15 Journals Publishing COVID-19 Research', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Number of Publications', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Journal', fontsize=12)\\n\",\n",
    "    \"plt.gca().invert_yaxis()\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('\\\\nTop 15 journals:')\\n\",\n",
    "    \"print(top_journals)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.3 Source Distribution\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Top sources\\n\",\n",
    "    \"top_sources = df_clean['source_x'].value_counts().head(10)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"plt.pie(top_sources.values, labels=top_sources.index, autopct='%1.1f%%',\\n\",\n",
    "    \"        startangle=90, colors=sns.color_palette('Set3'))\\n\",\n",
    "    \"plt.title('Distribution of Papers by Source (Top 10)', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.axis('equal')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('\\\\nSource distribution:')\\n\",\n",
    "    \"print(top_sources)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.4 Abstract Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Abstract word count distribution\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"plt.hist(df_clean['abstract_word_count'][df_clean['abstract_word_count'] > 0], \\n\",\n",
    "    \"         bins=50, color='skyblue', edgecolor='black')\\n\",\n",
    "    \"plt.title('Distribution of Abstract Word Counts', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Word Count', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Frequency', fontsize=12)\\n\",\n",
    "    \"plt.axvline(df_clean['abstract_word_count'].mean(), color='red', \\n\",\n",
    "    \"            linestyle='--', label=f'Mean: {df_clean[\\\"abstract_word_count\\\"].mean():.0f}')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f'Average abstract length: {df_clean[\\\"abstract_word_count\\\"].mean():.1f} words')\\n\",\n",
    "    \"print(f'Median abstract length: {df_clean[\\\"abstract_word_count\\\"].median():.1f} words')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.5 Text Analysis - Word Cloud\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate word cloud from titles\\n\",\n",
    "    \"all_titles = ' '.join(df_clean['title'].dropna().astype(str).tolist())\\n\",\n",
    "    \"\\n\",\n",
    "    \"wordcloud = WordCloud(\\n\",\n",
    "    \"    width=1600,\\n\",\n",
    "    \"    height=800,\\n\",\n",
    "    \"    background_color='white',\\n\",\n",
    "    \"    colormap='viridis',\\n\",\n",
    "    \"    max_words=100\\n\",\n",
    "    \").generate(all_titles)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(16, 8))\\n\",\n",
    "    \"plt.imshow(wordcloud, interpolation='bilinear')\\n\",\n",
    "    \"plt.axis('off')\\n\",\n",
    "    \"plt.title('Most Common Words in Paper Titles', fontsize=18, fontweight='bold', pad=20)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4.6 Most Common Words\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Extract common words from titles\\n\",\n",
    "    \"def get_common_words(text_series, top_n=20):\\n\",\n",
    "    \"    all_text = ' '.join(text_series.dropna().astype(str).tolist())\\n\",\n",
    "    \"    words = re.findall(r'\\\\b[a-z]{4,}\\\\b', all_text.lower())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    stop_words = {'with', 'from', 'that', 'this', 'have', 'been', 'were',\\n\",\n",
    "    \"                 'their', 'which', 'about', 'there', 'these', 'would'}\\n\",\n",
    "    \"    words = [w for w in words if w not in stop_words]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    word_counts = Counter(words)\\n\",\n",
    "    \"    return word_counts.most_common(top_n)\\n\",\n",
    "    \"\\n\",\n",
    "    \"common_words = get_common_words(df_clean['title'], top_n=20)\\n\",\n",
    "    \"words_df = pd.DataFrame(common_words, columns=['Word', 'Count'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"plt.barh(range(len(words_df)), words_df['Count'], color='teal')\\n\",\n",
    "    \"plt.yticks(range(len(words_df)), words_df['Word'])\\n\",\n",
    "    \"plt.title('Top 20 Most Common Words in Titles', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Frequency', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Word', fontsize=12)\\n\",\n",
    "    \"plt.gca().invert_yaxis()\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('\\\\nTop 20 words:')\\n\",\n",
    "    \"print(words_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Summary Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print('='*60)\\n\",\n",
    "    \"print('CORD-19 DATASET SUMMARY')\\n\",\n",
    "    \"print('='*60)\\n\",\n",
    "    \"print(f'\\\\nTotal papers analyzed: {len(df_clean):,}')\\n\",\n",
    "    \"print(f'Date range: {int(df_clean[\\\"year\\\"].min())} - {int(df_clean[\\\"year\\\"].max())}')\\n\",\n",
    "    \"print(f'Unique journals: {df_clean[\\\"journal\\\"].nunique():,}')\\n\",\n",
    "    \"print(f'Papers with abstracts: {df_clean[\\\"abstract\\\"].notna().sum():,}')\\n\",\n",
    "    \"print(f'Average abstract length: {df_clean[\\\"abstract_word_count\\\"].mean():.1f} words')\\n\",\n",
    "    \"print(f'\\\\nMost productive year: {int(df_clean[\\\"year\\\"].mode()[0])}')\\n\",\n",
    "    \"print(f'Top journal: {df_clean[\\\"journal\\\"].mode()[0]}')\\n\",\n",
    "    \"print(f'Top source: {df_clean[\\\"source_x\\\"].mode()[0]}')\\n\",\n",
    "    \"print('='*60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Export Cleaned Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save cleaned dataset\\n\",\n",
    "    \"df_clean.to_csv('metadata_cleaned.csv', index=False)\\n\",\n",
    "    \"print('Cleaned dataset saved as metadata_cleaned.csv')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Conclusions\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Findings:\\n\",\n",
    "    \"1. **Publication Trends**: There was a significant surge in COVID-19 research publications during 2020-2021\\n\",\n",
    "    \"2. **Research Sources**: Multiple databases contribute to the dataset, showing collaborative research efforts\\n\",\n",
    "    \"3. **Journal Distribution**: Research is published across diverse journals, indicating broad scientific interest\\n\",\n",
    "    \"4. **Common Themes**: Based on title analysis, key research areas include viral transmission, treatment, and public health\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"- Build interactive Streamlit dashboard\\n\",\n",
    "    \"- Implement advanced text analysis\\n\",\n",
    "    \"- Add temporal trend analysis\\n\",\n",
    "    \"- Create author network visualization\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
